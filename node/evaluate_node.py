import base64
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage

from core.state import GraphState
from core.model import LanguageModelManager, ModelType
from utils.file_loader import load_analysis_files,load_visualization_files
from utils.logger import setup_logger

model_manager = LanguageModelManager()
llm = model_manager.get_model(ModelType.GOOGLE_FLASH)

def evaluate_node(state: GraphState) -> GraphState:
    """
    Evaluate a node in the graph state.

    Args:
        state (GraphState): The current state of the graph.

    Returns:
        GraphState: The updated state of the graph.
    """
    logger = setup_logger("evaluate_node.log")
    logger.info("Evaluating node...")

    # read the number from state
    number = state["number"]
    logger.info(f"execution number: {number}")
    report_content = load_analysis_files(number)
    image_list = load_visualization_files(number)
    # read the analysis plan from state
    plan = state["analysis_plan"]
    # construct the prompt:
    system_prompt_text = (
        "You are a data scientist and you are evaluating the reports and visualizations "
        "generated by the analysis agent. You will be provided with the analysis report "
        "and the visualizations. Your task is to evaluate the report and visualizations "
        "and provide feedback on their quality and relevance."
    )
    system_message = SystemMessage(content=system_prompt_text)
    human_prompt = []
    human_prompt_base_text = f"""Please base your evaluation on the following analysis report, data summary, and visualizations.
    Analysis Plan:
    {plan}
    Analysis Report and Data:
    {report_content}
    only return the evaluation result, do not return any other information.
    """ 
    human_prompt.append({"type": "text", "text": human_prompt_base_text})
    # Added images to the prompt
    image_base64 = load_visualization_files(number)

    for image in image_base64:
        human_prompt.append({
                "type": "image_url",
                "image_url": {"url": "data:image/png;base64," + image['base64']}
            })
    human_message = HumanMessage(content=human_prompt)
    result = llm.invoke([system_message, human_message])

    logger.info("Node evaluated successfully.")
    # print(f"Evaluation result: {result.content}")
    return {"evaluation_results": result.content}